{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 124 but got size 125 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 137\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m# X: M, N, B, T\u001b[39;00m\n\u001b[0;32m    136\u001b[0m Mask_temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(M_updata, [\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, B\u001b[39m*\u001b[39mT, M, N)\u001b[39m.\u001b[39mtype(dtype)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m--> 137\u001b[0m out \u001b[39m=\u001b[39m model(net_input, Mask_temp)\n\u001b[0;32m    138\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(out\u001b[39m.\u001b[39mreshape(B, T, M, N), [\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[0;32m    139\u001b[0m loss1 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mnorm(Y \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmul(X, M_updata) \u001b[39m-\u001b[39m C, \u001b[39m'\u001b[39m\u001b[39mfro\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32md:\\development\\anaconda\\envs\\deep-todo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\coding\\github_project\\study-MST\\simulation\\train_code\\architecture\\MST.py:284\u001b[0m, in \u001b[0;36mMST.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m i, (FeaUpSample, Fution, LeWinBlcok) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_layers):\n\u001b[0;32m    283\u001b[0m     fea \u001b[39m=\u001b[39m FeaUpSample(fea)\n\u001b[1;32m--> 284\u001b[0m     fea \u001b[39m=\u001b[39m Fution(torch\u001b[39m.\u001b[39;49mcat([fea, fea_encoder[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstage\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49mi]], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    285\u001b[0m     mask \u001b[39m=\u001b[39m masks[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m i]\n\u001b[0;32m    286\u001b[0m     fea \u001b[39m=\u001b[39m LeWinBlcok(fea, mask)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 124 but got size 125 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import mat73\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import torch\n",
    "import torch.optim\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "from architecture import MST\n",
    "torch.cuda.manual_seed(seed=666)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "device = torch.device('cuda')\n",
    "torch.cuda.manual_seed(seed=666)\n",
    "\n",
    "\n",
    "########################################### 辅助函数 ###########################################\n",
    "def thres_21(L, tau, M, N, B):\n",
    "    S = torch.sqrt(torch.sum(torch.mul(L, L), 2))\n",
    "    S[S == 0] = 1\n",
    "    T = 1 - tau / S\n",
    "    T[T < 0] = 0\n",
    "    R = T.reshape(M, N, 1).repeat((1, 1, B))\n",
    "    res = torch.mul(R, L)\n",
    "    return res\n",
    "\n",
    "\n",
    "################################ 读取数据 ################################\n",
    "YY= mat73.loadmat(\"./Data/T31UDQ/T31UDQ_20m_raw1.mat\")['T31UDQ_20m_raw1'] \n",
    "YY = np.double(YY)\n",
    "YY = YY/YY.max()\n",
    "Mask1_500 = mat73.loadmat(\"./Data/Mask1_500.mat\")['Mask1_500']\n",
    "Mask2_500 = mat73.loadmat(\"./Data/Mask2_500.mat\")['Mask2_500']\n",
    "\n",
    "Mask = np.copy(Mask2_500)\n",
    "Mask[ Mask != 0 ] = 1\n",
    "# Test1_Clean是干净图像，取的是4，2，0三个时相\n",
    "Test1_Clean = np.copy(YY[:, :, :, [4, 2, 0]])\n",
    "\n",
    "# 生成云图YY，含有6个时相\n",
    "Clean = YY[:, :, :, [4, 2, 0, 5, 3, 1]]\n",
    "YY = np.multiply((1 - Mask), (YY[:, :, :, [4, 2, 0, 5, 3, 1]])) + Mask\n",
    "Noisy = np.copy(YY)\n",
    "Cloud = np.copy(Mask)\n",
    "Mask = 1 - Cloud\n",
    "###########################################################################\n",
    "\n",
    "M, N, B, T = Noisy.shape\n",
    "Clean = torch.from_numpy(Clean.reshape(M, N, B, T)).to(device)\n",
    "Mask = torch.from_numpy(Mask.reshape(M, N, B, T)).to(device)  # 云=0\n",
    "Cloud = torch.from_numpy(Cloud.reshape(M, N, B, T)).to(device)  # 云=1\n",
    "Noisy = torch.from_numpy(Noisy.reshape(M, N, B, T)).to(device)\n",
    "\n",
    "\n",
    "################################ 全局设置 ################################\n",
    "def grid_combine(args_list):\n",
    "    for rate in args_list[0]:\n",
    "        for lambda2 in args_list[1]:\n",
    "            for rho in args_list[2]:\n",
    "                for alpha in args_list[3]:\n",
    "                    if rate == 125 and rho ==0.08 and alpha==1.03 :\n",
    "                        continue\n",
    "                    yield rate, lambda2, rho, alpha\n",
    "args_list = [\n",
    "    [125, 100],  # rate\n",
    "    [0.1],  # lambda2\n",
    "    [0.08, 0.06, 0.04],  # rho\n",
    "    [1.03, 1.025]  # alpha\n",
    "]\n",
    "condidates = [\n",
    "    # lambda1, lambda2, rho\n",
    "    # [6.0, 0.1, 0.12, 1.03]     # condidate2\n",
    "    # [12.5, 0.1, 0.1], \n",
    "    # [10.0, 0.1, 0.1], \n",
    "    # [7.50, 0.1, 0.1],  \n",
    "    # [10.0, 0.2, 0.1], \n",
    "    # [10.0, 0.4, 0.1], \n",
    "]\n",
    "condidates = [\n",
    "    # rate, lambda2, rho, alpha\n",
    "    # [90, 0.06, 0.06, 1.03],\n",
    "    # [95, 0.06, 0.08, 1.03],\n",
    "    # [88, 0.06, 0.08, 1.03],\n",
    "    # [90, 0.08, 0.08, 1.03],\n",
    "    [40, 0.4, 0.01, 1.03],\n",
    "    [40, 0.4, 0.01, 1.04],\n",
    "    [40, 0.4, 0.01, 1.02]\n",
    "]\n",
    "iter_num, epoch_num = 150, 200\n",
    "order = 0\n",
    "for rate, lambda2, rho, alpha in condidates:\n",
    "# for rate, lambda2, rho, alpha in grid_combine(args_list):\n",
    "    # rate = lambda1 / rho\n",
    "    lambda1 = rate * rho\n",
    "    iters = 0\n",
    "    order += 1\n",
    "    log_dir = \"./candidates-picardie-acc/order[%03d]-iter[%3d]-epoch[%3d]-rate[%.3f]-lambda2[%.3f]-rho[%.3f,%.3f]\" \\\n",
    "              % (order, iter_num, epoch_num, rate, lambda2, rho, alpha)\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    else:\n",
    "        continue\n",
    "    # rate, lambda2, rho, alpha = 125, 0.1, 0.08, 1.04\n",
    "    ################################ 初始化 ################################\n",
    "    Y = Noisy.clone()\n",
    "    X = Noisy.clone()\n",
    "    W = Noisy.clone()\n",
    "    C = torch.zeros(Y.shape).type(dtype).to(device)\n",
    "    M_updata = Mask.clone()\n",
    "    model = MST(dim=B*T, stage=2, num_blocks=[2, 2, 2]).cuda()\n",
    "    psnr = 0\n",
    "    s0_min = 10000\n",
    "    ################################ 子问题更新 ################################\n",
    "    while iters < iter_num:\n",
    "        # if iters >= 100 and psnr < 32:\n",
    "        #     break\n",
    "        iters += 1\n",
    "        ################################ 更新子问题X ################################\n",
    "        # if decrease and (iters % 4 == 0) and LR > 0.00001:\n",
    "        #     LR *= 0.9\n",
    "        LR = 0.0002\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.999))\n",
    "        # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [250], gamma=0.7, last_epoch=-1)\n",
    "        loss_history, loss1_history, loss2_history = [], [], []\n",
    "        epoch = 0\n",
    "        net_input = torch.permute(X, [2, 3, 0, 1]).reshape(1, B * T, M, N).type(dtype).to(device)\n",
    "        while epoch < epoch_num:\n",
    "            epoch += 1\n",
    "            optimizer.zero_grad()\n",
    "            # X: M, N, B, T\n",
    "            Mask_temp = torch.permute(M_updata, [2, 3, 1, 0]).reshape(1, B*T, M, N).type(dtype).to(device)\n",
    "            out = model(net_input, Mask_temp)\n",
    "            X = torch.permute(out.reshape(B, T, M, N), [2, 3, 0, 1])\n",
    "            loss1 = 1 / 2 * torch.norm(Y - torch.mul(X, M_updata) - C, 'fro') ** 2\n",
    "            loss2 = rho / 2 * torch.norm(X - W, 'fro') ** 2\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            loss_history.append(loss.item())\n",
    "            loss1_history.append(loss1.item())\n",
    "            loss2_history.append(loss2.item())\n",
    "            if epoch % 40 == 0:\n",
    "                print(\"\\tThe %03dth iters, the %03dth epoch, loss: %.5f\" % (iters, epoch, loss.item()))\n",
    "            Y, C, W, X = Y.detach(), C.detach(), W.detach(), X.detach()\n",
    "\n",
    "        Y, C, W, X = Y.detach(), C.detach(), W.detach(), X.detach()\n",
    "\n",
    "        ################################ 更新子问题W ################################\n",
    "        U, s, VH = torch.linalg.svd(X.reshape(M * N, B * T), full_matrices=False)  # B*T, M*N\n",
    "        s0 = s[0]\n",
    "        rho *= alpha\n",
    "        # if s0<s0_min: # s0处于不断下降的第一阶段\n",
    "        #     s0_min = s0\n",
    "        #     rho *= alpha\n",
    "        # else:\n",
    "        #     rho *= 1.02\n",
    "        rate = lambda1 / rho\n",
    "        print(\"s: \", s)\n",
    "        s = s - lambda1 / rho\n",
    "        s[s < 0] = 0\n",
    "        S = torch.diag(s)\n",
    "        W = torch.mm(torch.mm(U, S), VH).reshape(M, N, B, T)\n",
    "        ################################ 更新子问题C ################################\n",
    "        L = Y - torch.mul(X, M_updata)\n",
    "        for t in range(T):\n",
    "            C[:, :, :, t] = thres_21(L[:, :, :, t], lambda2, M, N, B)\n",
    "\n",
    "        ################################ 更新掩码M ################################\n",
    "        # B_mean = torch.mean(Y-X, dim=2).reshape(M, N, 1, T).repeat((1, 1, B, 1))\n",
    "        # M_updata[:, :, :, :3][torch.abs(B_mean[:, :, :, :3]) > 0.01] = 0   # M_update=1表示无云，M_update=0表示云\n",
    "        # if iters > 5:\n",
    "        #     M_updata[:, :, :, :3][torch.abs(B_mean[:, :, :, :3]) < 0.01] = 1\n",
    "\n",
    "        ################################ 进行指标评估 ################################\n",
    "        # mse = torch.sum((X - Clean) ** 2)\n",
    "        psnr = []\n",
    "        for t in range(3):\n",
    "            psnr_t = 0\n",
    "            for b in range(B):\n",
    "                psnr_t += compare_psnr(X[:, :, b, t].detach().cpu().numpy(), Clean[:, :, b, t].detach().cpu().numpy(), data_range=1)\n",
    "            psnr.append(psnr_t / B)\n",
    "        ssim = []\n",
    "        for t in range(3):\n",
    "            ssim_b = 0\n",
    "            for b in range(B):\n",
    "                ssim_b += compare_ssim(X[:, :, b, t].detach().cpu().numpy(), Clean[:, :, b, t].detach().cpu().numpy())\n",
    "            ssim.append(ssim_b / B)\n",
    "        # print(\"The %03dth iters, the %03dth epoch, loss: %.5f, mse: %.5f, psnr: %.5f, ssim: %.5f\" % (\n",
    "        #     iters, epoch, loss.item(), mse, psnr, ssim))\n",
    "\n",
    "        image_Clean = Clean.cpu().numpy()\n",
    "        image_Y = Y.cpu().numpy()\n",
    "        image_X = X.cpu().detach().numpy()\n",
    "        image_C = C.cpu().numpy()\n",
    "        image_M = M_updata.cpu().numpy()\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i in range(6):\n",
    "            plt.subplot(6, 6, 1 + i)\n",
    "            plt.title(\"Clean\")\n",
    "            plt.imshow(image_Clean[:, :, [4, 2, 0], i]*5)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(6, 6, 7 + i)\n",
    "            plt.title(\"X\")\n",
    "            plt.imshow(image_X[:, :, [4, 2, 0], i]*5)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(6, 6, 13 + i)\n",
    "            plt.title(\"Y\")\n",
    "            plt.imshow(image_Y[:, :, [4, 2, 0], i]*5)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(6, 6, 19 + i)\n",
    "            plt.title(\"Y-X\")\n",
    "            plt.imshow(image_Y[:, :, [4, 2, 0], i]*5 - image_X[:, :, [4, 2, 0], i]*5)\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(6, 6, 25 + i)\n",
    "            plt.title(\"C\")\n",
    "            plt.imshow(image_C[:, :, 0, i]*5, cmap='gray')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(6, 6, 31 + i)\n",
    "            plt.title(\"M_update\")\n",
    "            plt.imshow(image_M[:, :, 0, i], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        psnr1, psnr2, psnr3 = psnr\n",
    "        ssim1, ssim2, ssim3 = ssim\n",
    "        result_path = \"%s/iter[%03d, %03d]-pnsr[%.3f, %.3f, %.3f]-ssim[%.3f, %.3f, %.3f].png\" % (\n",
    "            log_dir, iters, epoch, psnr1, psnr2, psnr3, ssim1, ssim2, ssim3)\n",
    "        plt.savefig(result_path)\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(30, 60))\n",
    "        plt.subplot(6, 1, 1)\n",
    "        plt.title(\"total loss\")\n",
    "        plt.plot([i for i in range(len(loss_history[50:]))], loss_history[50:])\n",
    "\n",
    "        plt.subplot(6, 1, 2)\n",
    "        plt.title(\"loss1\")\n",
    "        plt.plot([i for i in range(len(loss1_history[50:]))], loss1_history[50:])\n",
    "\n",
    "        plt.subplot(6, 1, 3)\n",
    "        plt.title(\"loss2\")\n",
    "        plt.plot([i for i in range(len(loss2_history[50:]))], loss2_history[50:])\n",
    "\n",
    "        plt.subplot(6, 1, 4)\n",
    "        plt.title(\"total loss\")\n",
    "        plt.plot([i for i in range(len(loss_history))], loss_history)\n",
    "\n",
    "        plt.subplot(6, 1, 5)\n",
    "        plt.title(\"loss1\")\n",
    "        plt.plot([i for i in range(len(loss1_history))], loss1_history)\n",
    "\n",
    "        plt.subplot(6, 1, 6)\n",
    "        plt.title(\"loss2\")\n",
    "        plt.plot([i for i in range(len(loss2_history))], loss2_history)\n",
    "\n",
    "        loss_path = \"%s/iter[%03d, %03d]-LR[%f]-rate[%.3f]-s0[%.3f]-rho[%.3f]-loss[%.3f].png\" % (\n",
    "            log_dir, iters, epoch, LR, rate, s0, rho, loss.item())\n",
    "        plt.savefig(loss_path)\n",
    "        plt.clf()\n",
    "\n",
    "        plt.close()\n",
    "        scio.savemat(\"%s/recover_data.mat\" % log_dir, {\"recover_data\": image_X})\n",
    "    # decrease = True\n",
    "    # up = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, a, _ = torch.linalg.svd(X.reshape(M*N, B*T), full_matrices=False)  # B*T, M*N\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr = []\n",
    "for t in range(3):\n",
    "    psnr_b = 0\n",
    "    for b in range(B):\n",
    "        psnr_b += compare_psnr(image_X[:, :, b, t], Clean[:, :, b, t].detach().cpu().numpy(), data_range=1)\n",
    "    psnr_b /= B\n",
    "    psnr.append(psnr_b)\n",
    "print(psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scio.savemat(\"%s/recover_data.mat\" % log_dir, {\"recover_data\": image_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = scio.loadmat(\"%s/recover_data.mat\" % log_dir)[\"recover_data\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep-todo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e95cce7115af6d5c4f61b39ba0e9b0b918610ad54a2ec079c8fe6ce2b889e3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
