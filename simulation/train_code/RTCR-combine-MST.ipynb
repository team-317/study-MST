{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.5000, beta1 = 0.500, Rho1 = 1.0000, Rho2 = 0.1000\n",
      "\n",
      "The 0th iter is start...\n",
      "The 0th epoch, 0th iter, loss: 248641.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 001th iters, the 020th epoch, loss: 2542497768807596032.00000, mse: 2554465059025179136.00000, psnr: -114.32458, ssim: 0.48047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1th iter is start...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1585\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\development\\anaconda\\envs\\deep-todo\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:1081\u001b[0m, in \u001b[0;36mPyDB.enable_tracing\u001b[1;34m(self, thread_trace_func, apply_to_all_threads)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_eval_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1080\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe_eval_func()\n\u001b[1;32m-> 1081\u001b[0m     pydevd_tracing\u001b[39m.\u001b[39;49mSetTrace(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdummy_trace_dispatch)\n\u001b[0;32m   1083\u001b[0m     \u001b[39mif\u001b[39;00m IS_CPYTHON \u001b[39mand\u001b[39;00m apply_to_all_threads:\n\u001b[0;32m   1084\u001b[0m         pydevd_tracing\u001b[39m.\u001b[39mset_trace_to_threads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdummy_trace_dispatch)\n",
      "File \u001b[1;32md:\\development\\anaconda\\envs\\deep-todo\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:77\u001b[0m, in \u001b[0;36mSetTrace\u001b[1;34m(tracing_func)\u001b[0m\n\u001b[0;32m     74\u001b[0m _last_tracing_func_thread_local\u001b[39m.\u001b[39mtracing_func \u001b[39m=\u001b[39m tracing_func\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m tracing_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[39mif\u001b[39;00m set_trace_to_threads(tracing_func, thread_idents\u001b[39m=\u001b[39;49m[thread\u001b[39m.\u001b[39;49mget_ident()], create_dummy_thread\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     78\u001b[0m         \u001b[39m# If we can use our own tracer instead of the one from sys.settrace, do it (the reason\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[39m# is that this is faster than the Python version because we don't call\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         \u001b[39m# PyFrame_FastToLocalsWithError and PyFrame_LocalsToFast at each event!\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         \u001b[39m# (the difference can be huge when checking line events on frames as the\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         \u001b[39m# time increases based on the number of local variables in the scope)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         \u001b[39m# See: InternalCallTrampoline (on the C side) for details.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m# If it didn't work (or if it was None), use the Python version.\u001b[39;00m\n",
      "File \u001b[1;32md:\\development\\anaconda\\envs\\deep-todo\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd_tracing.py:345\u001b[0m, in \u001b[0;36mset_trace_to_threads\u001b[1;34m(tracing_func, thread_idents, create_dummy_thread)\u001b[0m\n\u001b[0;32m    343\u001b[0m start_new_thread \u001b[39m=\u001b[39m pydev_monkey\u001b[39m.\u001b[39mget_original_start_new_thread(thread)\n\u001b[0;32m    344\u001b[0m start_new_thread(increase_tracing_count, ())\n\u001b[1;32m--> 345\u001b[0m proceed\u001b[39m.\u001b[39;49macquire()  \u001b[39m# Only proceed after the release() is done.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m proceed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m# Note: The set_trace_func is not really used anymore in the C side.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from architecture import MST\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "def thre(a, tau):\n",
    "    x = a\n",
    "    x[ torch.abs(a) <= tau] = 0\n",
    "    return x\n",
    "\n",
    "################################ 全局设置 ################################\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.cuda.FloatTensor\n",
    "eigen_num, lr = 4, 0.0001\n",
    "################################ 重新读取数据 ################################\n",
    "Data = scio.loadmat(\"./SimuData.mat\")\n",
    "Clean, Mask, Cloud, Noisy = Data[\"Clean\"], Data[\"Mask\"], Data[\"Cloud\"], Data[\"Noisy\"]\n",
    "M, N, = 384, 384\n",
    "B, T = 4, 4\n",
    "# 相邻四张图像为同一个时间，因而初始的维度为M, N, T, B\n",
    "Clean = torch.from_numpy(Clean[:M, :N, :].reshape(M, N, T, B)).to(device)\n",
    "Mask = torch.from_numpy(Mask[:M, :N, :].reshape(M, N, T, B)).to(device)      # 云=0\n",
    "Cloud = torch.from_numpy(Cloud[:M, :N, :].reshape(M, N, T, B)).to(device)    # 云=1\n",
    "Noisy = torch.from_numpy(Noisy[:M, :N, :].reshape(M, N, T, B)).to(device)\n",
    "\n",
    "# 进行维度调整：M, N, B, T\n",
    "Clean = torch.permute(Clean, [0, 1, 3, 2])\n",
    "Mask = torch.permute(Mask, [0, 1, 3, 2])\n",
    "Cloud = torch.permute(Cloud, [0, 1, 3, 2])\n",
    "Noisy = torch.permute(Noisy, [0, 1, 3, 2])\n",
    "\n",
    "# 将第二张观测图像设置为干净图像\n",
    "Cloud[:, :, :, 1] = 0\n",
    "Mask[:, :, :, 1] = 1\n",
    "Noisy[:, :, :, 1] = Clean[:, :, :, 1]\n",
    "\n",
    "YY = Noisy.clone()\n",
    "Mask = Cloud.clone()\n",
    "h, w = M, N\n",
    "\n",
    "################################ 初始化 ################################\n",
    "alpha, beta1, rho1, rho2 = 0.5, 0.5, 1, 0.1\n",
    "M, N, B, T = YY.shape\n",
    "SS = torch.zeros(YY.shape).type(dtype).to(device)\n",
    "k_subspacce = 4\n",
    "MM = torch.zeros((M, N, k_subspacce, T)).type(dtype).to(device)\n",
    "Gam1 = torch.zeros((M, N, k_subspacce, T)).type(dtype).to(device)\n",
    "Gam2 = torch.zeros((M, N, B, T)).type(dtype).to(device)\n",
    "XX = torch.clone(YY).type(dtype).to(device)\n",
    "Rec = torch.clone(YY).type(dtype).to(device)\n",
    "\n",
    "beta2 = beta1\n",
    "print( 'Alpha = %2.4f, beta1 = %2.3f, Rho1 = %2.4f, Rho2 = %2.4f\\n'%(alpha,beta1, rho1,rho2))\n",
    "\n",
    "index1 = (Mask != 0)\n",
    "index2 = (Mask == 0)\n",
    "\n",
    "A_sum = torch.zeros((B, k_subspacce, T)).type(dtype).to(device)   \n",
    "Z_sum = torch.zeros((M*N, k_subspacce, T)).type(dtype).to(device)\n",
    "T2 = torch.zeros((M, N, B, T)).type(dtype).to(device)\n",
    "\n",
    "model = MST(dim=16).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999))\n",
    "iters = 0\n",
    "order = 0\n",
    "log_dir = \"logs-order[%d]\" % order\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "############################# 迭代更新 #############################\n",
    "while iters < 500:\n",
    "    print(\"The %dth iter is start...\" % iters)\n",
    "    # 更新子问题F_k\n",
    "    for i in range(T):\n",
    "        Y = torch.reshape( XX[:, :, :, i] + Gam2[:, :, :, i]/rho2, (M*N, B) ).T\n",
    "        Y = Y.type(dtype).to(device)\n",
    "        if iters == 0:\n",
    "            A, _, _ = torch.linalg.svd(Y, full_matrices=False)\n",
    "            A = A[:, :k_subspacce]\n",
    "            A_sum[:, :, i] = torch.clone(A)\n",
    "        else:\n",
    "            result = torch.mm(Z_sum[:, :, i].T, Y.T)\n",
    "            A1, _, A2H = torch.linalg.svd(result, full_matrices=False)\n",
    "            A2 = A2H.T\n",
    "            A = torch.mm(A2, A1.T)\n",
    "            A = A[:, :k_subspacce]\n",
    "            A_sum[:, :, i] = torch.clone(A)\n",
    "    \n",
    "###################################################################\n",
    "    ## 2 更新子问题——A_k， 使用gdd进行更新\n",
    "    # net = gdd(input_depth, num_output_channels,\n",
    "    #     num_channels_down = num_channels,\n",
    "    #     num_channels_up = num_channels,\n",
    "    #     num_channels_skip = num_channels,  \n",
    "    #     filter_size_up = 3, filter_size_down = 3, filter_skip_size=1,\n",
    "    #     upsample_mode='bilinear', # downsample_mode='avg',\n",
    "    #     need1x1_up=False,\n",
    "    #     need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype).to(device)\n",
    "    # OPT_OVER =  'net'\n",
    "    # p = get_params(OPT_OVER, net, noise)\n",
    "    # optimizer = torch.optim.Adam(p, lr=lr)\n",
    "\n",
    "    loss = 0\n",
    "    torch.set_grad_enabled(True)\n",
    "    epoch = 20\n",
    "    loss_history = []\n",
    "    for i in range(epoch):\n",
    "        optimizer.zero_grad()\n",
    "        # Z_sum = net(G, noise).reshape((M*N, k_subspacce, T))\n",
    "        Y_temp = torch.permute(YY, [2, 3, 0, 1]).reshape(1, B * T, M, N).type(dtype).to(device)\n",
    "        Mask_temp = torch.permute(Mask, [2, 3, 1, 0]).reshape(1, B*T, M, N).type(dtype).to(device)\n",
    "        out = model(Y_temp, Mask_temp)\n",
    "        Z_sum = torch.permute(out.reshape(B, T, M, N), [2, 3, 0, 1]).reshape(M*N, B, T).type(dtype).to(device)\n",
    "        ## 计算损失值\n",
    "        loss = 0\n",
    "        for t in range(T):\n",
    "            A = A_sum[:, :, t]\n",
    "            Y = torch.reshape( XX[:, :, :, t] + Gam2[:, :, :, t]/rho2, (M*N, B) ).T\n",
    "            Z = Z_sum[:, :, t].T\n",
    "\n",
    "            part1 = rho2/2 * torch.norm( torch.mm(A.T, Y) - Z )**2\n",
    "            part2 = rho1/2 * torch.norm( torch.reshape(MM[:, :, :, t] + Gam1[:, :, :,t] / rho1, (M*N, k_subspacce)).T - Z ) ** 2\n",
    "            loss_i = part1 + part2\n",
    "            loss += loss_i\n",
    "        if i % 40 == 0:\n",
    "            print(\"The %dth epoch, %dth iter, loss: %.5f\" % (iters, i, loss.item()))\n",
    "        loss.backward()\n",
    "        loss_history.append(loss.item())\n",
    "        YY = YY.detach()\n",
    "        Rec = Rec.detach()\n",
    "        SS = SS.detach()\n",
    "        optimizer.step()\n",
    "    \n",
    "    for t in range(T):\n",
    "        A = A_sum[:, :, t]\n",
    "        Z = Z_sum[:, :, t].T\n",
    "        Rec[:, :, :, t] = torch.reshape(torch.mm(A, Z).T, (M, N, B))\n",
    "###############################################################\n",
    "    \n",
    "    YY = YY.detach()\n",
    "    Rec = Rec.detach()\n",
    "    SS = SS.detach()\n",
    "    A_sum = A_sum.detach()\n",
    "    Z_sum = Z_sum.detach()\n",
    "\n",
    "    ## 3 更新子问题——W_k\n",
    "    sv, p, r = 10, B, 36\n",
    "    temp = torch.reshape( torch.reshape(Z_sum, (M, N, k_subspacce, T))  \n",
    "            - Gam1/rho1, (M*N, k_subspacce*T))\n",
    "    U, sigma, VH = torch.linalg.svd(temp, full_matrices=False)\n",
    "    V = VH.T\n",
    "    svp = min(sum(sigma > alpha/rho1), r)\n",
    "\n",
    "    if svp < sv:\n",
    "        sv = min(p, svp+1)\n",
    "    else:\n",
    "        sv = min(p, svp+torch.round(torch.tensor(0.05*p).type(dtype)))\n",
    "    L_temp = torch.mm(U[:, :svp], torch.diag(sigma[:svp] - alpha/rho1))\n",
    "    L = torch.mm(L_temp, V[:, :svp].T) \n",
    "    MM = L.reshape((M, N, k_subspacce, T)) \n",
    "\n",
    "    ## 4 更新子问题 C_K+1\n",
    "    SS = thre(YY - XX, beta2)\n",
    "\n",
    "    ## 5 更新子问题 X_k+1 \n",
    "    XX_last = torch.clone(XX)\n",
    "    XX = ( torch.mul((YY - SS), (1 - Mask)) + rho2*Rec - Gam2 ) / ((1 - Mask) + rho2*torch.ones(YY.shape).to(device))\n",
    "    ## 6 更新子问题-拉格朗日乘子Pi和Qi\n",
    "    Gam1 = Gam1 + rho1*(MM - Z_sum.reshape((M, N, k_subspacce, T)))\n",
    "    Gam2 = Gam2 + rho2*(XX - Rec)\n",
    "\n",
    "    iters += 1\n",
    "\n",
    "    ####################### 评估指标，记录日志 #######################\n",
    "    mse = torch.sum((XX - Clean) ** 2)\n",
    "    Recover = torch.mul(YY, Mask) + torch.mul(XX, 1 - Mask)\n",
    "    psnr_rec = compare_psnr(Recover.detach().cpu().numpy(), Clean.detach().cpu().numpy(), data_range=2)\n",
    "    psnr = compare_psnr(XX.detach().cpu().numpy(), Clean.detach().cpu().numpy(), data_range=2)\n",
    "    ssim = 0\n",
    "    for k in range(B):\n",
    "        for l in range(T):\n",
    "            ssim += compare_ssim(XX[:, :, k, l].detach().cpu().numpy(), Clean[:, :, k, l].detach().cpu().numpy())\n",
    "    ssim = ssim / (B * T)\n",
    "    print(\"The %03dth iters, the %03dth epoch, loss: %.5f, mse: %.5f, psnr: %.5f, ssim: %.5f\" % (\n",
    "        iters, epoch, loss.item(), mse, psnr, ssim))\n",
    "\n",
    "    image_Clean = Clean.cpu().numpy()\n",
    "    image_Y = YY.cpu().numpy()\n",
    "    image_X = XX.cpu().detach().numpy()\n",
    "    image_C = SS.cpu().numpy()\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(4):\n",
    "        plt.subplot(5, 4, 1 + i)\n",
    "        plt.title(\"Clean\")\n",
    "        plt.imshow(image_Clean[:, :, [3, 2, 0], i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(5, 4, 5 + i)\n",
    "        plt.title(\"X\")\n",
    "        plt.imshow(image_X[:, :, [3, 2, 0], i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(5, 4, 9 + i)\n",
    "        plt.title(\"Y\")\n",
    "        plt.imshow(image_Y[:, :, [3, 2, 0], i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(5, 4, 13 + i)\n",
    "        plt.title(\"Y-X\")\n",
    "        plt.imshow(image_Y[:, :, [3, 2, 0], i] - image_X[:, :, [3, 2, 0], i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(5, 4, 17 + i)\n",
    "        plt.title(\"C\")\n",
    "        plt.imshow(image_C[:, :, 0, i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    result_path = \"%s/iter[%03d, %03d]-pnsr[%.3f, %.3f]-ssim[%.3f]-mse[%.5E]-loss[%.5E].png\" % (\n",
    "        log_dir, iters, epoch, psnr, psnr_rec, ssim, mse, loss.item())\n",
    "    plt.savefig(result_path)\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(30, 60))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(\"total loss\")\n",
    "    plt.plot([i for i in range(len(loss_history[50:]))], loss_history[50:])\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title(\"total loss\")\n",
    "    plt.plot([i for i in range(len(loss_history))], loss_history)\n",
    "\n",
    "    loss_path = \"%s/iter[%03d, %03d]-LR[%f]-losss[%.5E].png\" % (\n",
    "        log_dir, iters, epoch, lr, loss.item())\n",
    "    plt.savefig(loss_path)\n",
    "    plt.clf()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "## 计算评估指标\n",
    "mse = torch.sum((XX - Clean)**2)\n",
    "psnr = compare_psnr(XX.detach().cpu().numpy(), Clean.detach().cpu().numpy(), data_range=2)\n",
    "ssim = 0\n",
    "for k in range(B):\n",
    "    for l in range(T):\n",
    "        ssim += compare_ssim(XX[:, :, k, l].detach().cpu().numpy(), Clean[:, :, k, l].detach().cpu().numpy())\n",
    "print(\"The %dth epoch, mse: %.5f, psnr: %.5f, ssim: %.5f\" % (iters, mse, psnr, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可展示的图像：观测图像YY、云影SS、恢复图像XX、掩码Mask\n",
    "image_Clean = Clean.cpu().numpy()\n",
    "image_YY = YY.cpu().numpy()\n",
    "Rec = XX.clone()\n",
    "index_ = Mask == 0\n",
    "Rec[index_] = YY[index_]\n",
    "image_XX = Rec.cpu().numpy()\n",
    "image_SS = SS.cpu().numpy()\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(4):\n",
    "\n",
    "    plt.subplot(4,4,1+i)\n",
    "    plt.imshow(image_Clean[:,:, [3,2,0], i])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(4,4,5+i)\n",
    "    plt.imshow(image_YY[:,:,[3, 2, 0], i ])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(4,4,9+i)\n",
    "    plt.imshow(image_XX[:,:,[3, 2, 0],i])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(4,4,13+i)\n",
    "    plt.imshow((image_Clean-image_XX)[:,:,[3, 2, 0],i])\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "## 计算评估指标\n",
    "mse = torch.sum((Rec - Clean)**2)\n",
    "psnr = compare_psnr(Rec.detach().cpu().numpy(), Clean.detach().cpu().numpy(), data_range=2)\n",
    "ssim = 0\n",
    "for k in range(B):\n",
    "    for l in range(T):\n",
    "        ssim += compare_ssim(Rec[:, :, k, l].detach().cpu().numpy(), Clean[:, :, k, l].detach().cpu().numpy())\n",
    "print(\"The %dth epoch, mse: %.5f, psnr: %.5f, ssim: %.5f\" % (iters, mse, psnr, ssim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('deep-todo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e95cce7115af6d5c4f61b39ba0e9b0b918610ad54a2ec079c8fe6ce2b889e3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
